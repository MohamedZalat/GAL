{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zalat\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\zalat\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\zalat\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\zalat\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\zalat\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\zalat\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total pos class (should be 32) = 67\n",
      "\n",
      "centroids_set shape should be >= seed_set shape. If it doesn't then there is something wrong.\n",
      "centroids_set shape = \n",
      "(209, 10)\n",
      "seed_set shape = \n",
      "(209, 10)\n",
      "Is there a duplicated index in the unlabelled set?\n",
      "False\n",
      "Is there a duplicated index in the seed set?\n",
      "False\n",
      "Is there a positive example in our seed set?\n",
      "True\n",
      "Do X_unlabelled and y_unlabelled have the same size?\n",
      "X_unlabelled = 1879,\t y_unlabelled = 1879\n",
      "Negative example cost = 0.0430622009569378\n",
      "Positive example cost = 0.9569377990430622\n",
      "Number of Positive examples in seed set = 9\n",
      "[0 1]\n",
      "F1 score = 0.05617977528089888\n",
      "F1 score = 0.06097560975609757\n",
      "F1 score = 0.05670103092783506\n",
      "F1 score = 0.056847545219638244\n",
      "F1 score = 0.05670103092783506\n",
      "F1 score = 0.06134969325153375\n",
      "F1 score = 0.06060606060606061\n",
      "F1 score = 0.062111801242236024\n",
      "F1 score = 0.05665722379603399\n",
      "F1 score = 0.06024096385542168\n",
      "F1 score = 0.058997050147492625\n",
      "F1 score = 0.05882352941176471\n",
      "F1 score = 0.05813953488372092\n",
      "F1 score = 0.059139784946236555\n",
      "F1 score = 0.05612244897959184\n",
      "F1 score = 0.05813953488372092\n",
      "F1 score = 0.06060606060606061\n",
      "F1 score = 0.05797101449275362\n",
      "F1 score = 0.057636887608069155\n",
      "F1 score = 0.05730659025787965\n",
      "F1 score = 0.05813953488372092\n",
      "F1 score = 0.05882352941176471\n",
      "F1 score = 0.05813953488372092\n",
      "F1 score = 0.05797101449275362\n",
      "F1 score = 0.05699481865284974\n",
      "F1 score = 0.057894736842105256\n",
      "F1 score = 0.060790273556231\n",
      "F1 score = 0.060422960725075525\n",
      "F1 score = 0.057894736842105256\n",
      "F1 score = 0.06116207951070336\n",
      "F1 score = 0.06060606060606061\n",
      "F1 score = 0.06024096385542168\n",
      "F1 score = 0.0625\n",
      "F1 score = 0.06179775280898876\n",
      "F1 score = 0.061111111111111116\n",
      "F1 score = 0.06395348837209303\n",
      "F1 score = 0.06197183098591549\n",
      "F1 score = 0.06197183098591549\n",
      "F1 score = 0.05681818181818182\n",
      "F1 score = 0.06094182825484764\n",
      "F1 score = 0.05714285714285715\n",
      "F1 score = 0.05665722379603399\n",
      "F1 score = 0.0625\n",
      "F1 score = 0.059880239520958084\n",
      "F1 score = 0.06578947368421052\n",
      "F1 score = 0.06779661016949153\n",
      "F1 score = 0.06430868167202572\n",
      "F1 score = 0.06734006734006734\n",
      "F1 score = 0.0634920634920635\n",
      "F1 score = 0.06734006734006734\n",
      "F1 score = 0.05626598465473146\n",
      "F1 score = 0.07017543859649122\n",
      "F1 score = 0.06472491909385113\n",
      "F1 score = 0.072992700729927\n",
      "F1 score = 0.06557377049180328\n",
      "F1 score = 0.05774278215223097\n",
      "F1 score = 0.056555269922879174\n",
      "F1 score = 0.057894736842105256\n",
      "F1 score = 0.05774278215223097\n",
      "F1 score = 0.07220216606498195\n",
      "F1 score = 0.07352941176470588\n",
      "F1 score = 0.05509641873278237\n",
      "F1 score = 0.07194244604316546\n",
      "F1 score = 0.05699481865284974\n",
      "F1 score = 0.058201058201058205\n",
      "F1 score = 0.06825938566552901\n",
      "F1 score = 0.07462686567164178\n",
      "F1 score = 0.06920415224913494\n",
      "F1 score = 0.05945945945945946\n",
      "F1 score = 0.06896551724137931\n",
      "F1 score = 0.07462686567164178\n",
      "F1 score = 0.059945504087193464\n",
      "F1 score = 0.0749063670411985\n",
      "F1 score = 0.0558659217877095\n",
      "F1 score = 0.055248618784530384\n",
      "F1 score = 0.0502283105022831\n",
      "F1 score = 0.07547169811320756\n",
      "F1 score = 0.07633587786259542\n",
      "F1 score = 0.058997050147492625\n",
      "F1 score = 0.0763888888888889\n",
      "F1 score = 0.07518796992481204\n",
      "F1 score = 0.07633587786259542\n",
      "F1 score = 0.07746478873239437\n",
      "F1 score = 0.07547169811320756\n",
      "F1 score = 0.07692307692307691\n",
      "F1 score = 0.07220216606498195\n",
      "F1 score = 0.054945054945054944\n",
      "F1 score = 0.055248618784530384\n",
      "F1 score = 0.05847953216374269\n",
      "F1 score = 0.0558659217877095\n",
      "F1 score = 0.05830903790087463\n",
      "F1 score = 0.054945054945054944\n",
      "F1 score = 0.055248618784530384\n",
      "F1 score = 0.0749063670411985\n",
      "F1 score = 0.05602240896358543\n",
      "F1 score = 0.05602240896358543\n",
      "F1 score = 0.07575757575757575\n",
      "F1 score = 0.05555555555555556\n",
      "F1 score = 0.07782101167315175\n",
      "F1 score = 0.07575757575757575\n",
      "F1 score = 0.07547169811320756\n",
      "F1 score = 0.04891304347826087\n",
      "F1 score = 0.053908355795148244\n",
      "F1 score = 0.053908355795148244\n",
      "F1 score = 0.053412462908011875\n",
      "F1 score = 0.052173913043478265\n",
      "F1 score = 0.05013927576601672\n",
      "F1 score = 0.053475935828877004\n",
      "F1 score = 0.05025125628140704\n",
      "F1 score = 0.046511627906976744\n"
     ]
    }
   ],
   "source": [
    "#--------------------------------------------------------------------------------\n",
    "#\n",
    "# Project implementation.\n",
    "#\n",
    "#--------------------------------------------------------------------------------\n",
    "# !pip install neupy\n",
    "# !pip install --upgrade mlxtend\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from scipy.spatial.distance import cdist\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, \\\n",
    "    recall_score, roc_curve, precision_recall_curve, make_scorer, f1_score\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from random import random\n",
    "import os\n",
    "from warnings import simplefilter\n",
    "\n",
    "# ignore all future warnings.\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "simplefilter(action='ignore', category=DeprecationWarning)\n",
    "\n",
    "#--------------------------------------------------------------------------------\n",
    "np.random.seed(0)\n",
    "\n",
    "#--------------------------------------------------------------------------------\n",
    "BASE_DIR = F\"C:/Users/zalat/Downloads/Directed Studies/Experiments/Abalone19/GAL\"\n",
    "SAVE_DIR = F\"C:/Users/zalat/Downloads/Directed Studies/Experiments/Results/\"\n",
    "CSV_FILE_TRAINING = F\"abalone_csv.csv\"\n",
    "# CSV_FILE_CALIBRATION = F\"csv_result-Descriptors_Calibration.csv\"\n",
    "POSITIVE_LABEL = 1\n",
    "NEGATIVE_LABEL = 0\n",
    "CLASS_COLUMN = 'class'\n",
    "N = 4000\n",
    "init_beta = 0.01 ** (1/float(N))\n",
    "MAX_ITER = 100000\n",
    "ABALONE_AGE = 16\n",
    "    \n",
    "#--------------------------------------------------------------------------------\n",
    "class OnlinePipeline(Pipeline):\n",
    "    def online_fit(self, X, y):\n",
    "        Xt = X\n",
    "        for name, transform in self.steps[:-1]:\n",
    "            Xt = transform.transform(Xt)\n",
    "        name, estimator = self.steps[-1]\n",
    "        return estimator.fit(Xt, y)\n",
    "    \n",
    "    def bic(self, X):\n",
    "        name, estimator = self.steps[-1]\n",
    "        return estimator.bic(X)\n",
    "    \n",
    "    def score_samples(self, X):\n",
    "        name, estimator = self.steps[-1]\n",
    "        return estimator.score_samples(X)\n",
    "\n",
    "#--------------------------------------------------------------------------------\n",
    "def import_csv(file_path):\n",
    "    return pd.read_csv(file_path)\n",
    "\n",
    "#--------------------------------------------------------------------------------\n",
    "def concatenate_frames(frames):\n",
    "    return pd.concat(frames, ignore_index=True)\n",
    "\n",
    "#--------------------------------------------------------------------------------\n",
    "def _create_model_instance(model):\n",
    "    scaler = MinMaxScaler((-1, 1))\n",
    "    \n",
    "    return OnlinePipeline([('scaler', scaler),\n",
    "                           ('model', model)])\n",
    "\n",
    "#--------------------------------------------------------------------------------\n",
    "def create_discriminative_model_instance(class_weight=None):\n",
    "    # Creates an instance of the model with the given error tolerance,\n",
    "    # regularization hyperparameter C, intercept_scaling for bias and \n",
    "    # class_weight 'balanced' for multiplying the cost of each point with the \n",
    "    # inverse of its respective class proportion (by default there is no \n",
    "    # weighting).\n",
    "    #\n",
    "    # !!! NOTE !!!\n",
    "    # For adding a custom weight to the examples, use a dictionary mapping the\n",
    "    # class to the cost. \n",
    "    #\n",
    "    # Example: {'P': cost_of_positive, 'N': cost_of_negative}\n",
    "\n",
    "#     model = LinearSVC(tol=tol, C=C, intercept_scaling=intercept_scaling,\n",
    "#                       class_weight=class_weight, loss='hinge', max_iter=MAX_ITER)\n",
    "    \n",
    "    model = SVC(class_weight=class_weight, probability=True)\n",
    "    \n",
    "    # Wrap the model with a calibrated classifier to get Pratt scaled posteriors.\n",
    "#     model = CalibratedClassifierCV(model)\n",
    "\n",
    "    return _create_model_instance(model)\n",
    "\n",
    "#--------------------------------------------------------------------------------\n",
    "def create_generative_model_instance(n_components=1):\n",
    "    # Creates an instance of a GMM model with the specified number of gaussian \n",
    "    # components.\n",
    "    model = GaussianMixture(n_components, covariance_type='tied')\n",
    "    return _create_model_instance(model)\n",
    "\n",
    "#--------------------------------------------------------------------------------\n",
    "def calculate_entropy(discriminative_model, unlabelled_X):\n",
    "    # Returns the entropy of each sample in unlabelled_X with respect to the \n",
    "    # given discriminative model. (H(Y|x) for x in unlabelled_X)\n",
    "    \n",
    "    # 1) Get P(Ymin|x).\n",
    "    posterior_probs = discriminative_model.predict_proba(unlabelled_X)[:, -1]\n",
    "    \n",
    "    # 2) Calculate entropy (H(Y|x)).\n",
    "    entropy = np.multiply(posterior_probs, np.log(posterior_probs))\n",
    "    \n",
    "    return entropy\n",
    "\n",
    "#--------------------------------------------------------------------------------\n",
    "def _uncertainty_score(discriminative_model, generative_model,\n",
    "                       unlabelled_X, *pargs, **kwargs):\n",
    "    # Returns the entropy of each sample in unlabelled_X with respect to the \n",
    "    # given discriminative model. (H(Y|x) for x in unlabelled_X)\n",
    "    return calculate_entropy(discriminative_model, unlabelled_X)\n",
    "\n",
    "#--------------------------------------------------------------------------------\n",
    "def _likelihood_score(discriminative_model, generative_model,\n",
    "                       unlabelled_X, *pargs, **kwargs):\n",
    "    # Returns (1 - P(x|Ymin)) for each point x in unlabelled_X.\n",
    "    \n",
    "    # Get the weighted log likelihood of each sample. (log(P(x|Ymin))).\n",
    "    log_likelihood = generative_model.score_samples(unlabelled_X)\n",
    "    \n",
    "    # Convert to the likelihood. (P(x|Ymin)).\n",
    "    likelihood = np.exp(log_likelihood) \n",
    "    \n",
    "    return 1 - likelihood\n",
    "    \n",
    "#--------------------------------------------------------------------------------\n",
    "def _GAL_score(discriminative_model, generative_model, unlabelled_X, iteration,\n",
    "               *pargs, **kwargs):\n",
    "    # Calculates the GAL score using the discriminative and generative model using\n",
    "    # the unlabelled batch provided in unlabelled_X, and returns the score of\n",
    "    # each point in the batch.\n",
    "    \n",
    "    # Calculate entropy (H(Y|x)).\n",
    "    entropy = calculate_entropy(discriminative_model, unlabelled_X)\n",
    "    \n",
    "     # Get the weighted log likelihood of each sample. (log(P(x|Ymin))).\n",
    "    log_likelihood = generative_model.score_samples(unlabelled_X)\n",
    "    \n",
    "    # Convert to the likelihood. (P(x|Ymin)).\n",
    "    likelihood = np.exp(log_likelihood) \n",
    "    \n",
    "    # Compute P(x|Ymin)^Beta(iteration).\n",
    "    if random() > 0.05:\n",
    "        exploitation_factor = likelihood ** (init_beta ** float(iteration))\n",
    "    else:\n",
    "        exploitation_factor = (1 - likelihood) ** (init_beta ** float(iteration))\n",
    "    \n",
    "    # Score = H(Y|x) * P(x|Ymin) ^ Beta(t).\n",
    "    score = np.multiply(entropy, exploitation_factor)\n",
    "    \n",
    "    return score\n",
    "\n",
    "#--------------------------------------------------------------------------------\n",
    "def _select_point_from_batch(discriminative_model, generative_model, \n",
    "                             unlabelled_df, iteration, scoring_function):\n",
    "    # Calculates the score associated with each point in a batch of 59 points\n",
    "    # from the unlabelled_df points at a given iteration and returns the new\n",
    "    # set of unlabelled points (U - selected_point) and selected point along \n",
    "    # with its respective class. The score is calculated by using the passed\n",
    "    # scoring function.\n",
    "    batch = unlabelled_df.sample(min(59, len(unlabelled_df)))\n",
    "    unlabelled_X = batch.drop([CLASS_COLUMN], 1)\n",
    "    unlabelled_y = batch[CLASS_COLUMN]\n",
    "    \n",
    "    score = scoring_function(discriminative_model, generative_model,\n",
    "                             unlabelled_X, iteration)\n",
    "    \n",
    "    selected_point_idx = np.argmax(score)\n",
    "    \n",
    "    # Get the selected point and class label.\n",
    "    selected_point = unlabelled_X.iloc[selected_point_idx]\n",
    "    selected_class = unlabelled_y.iloc[selected_point_idx]\n",
    "    \n",
    "    # Remove the selected point from the unlabelled pool.\n",
    "    new_set = unlabelled_df.drop(selected_point.name)\n",
    "    \n",
    "    return new_set, selected_point, selected_class\n",
    "\n",
    "#--------------------------------------------------------------------------------\n",
    "def select_point_from_batch_GAL(discriminative_model, generative_model, \n",
    "                                unlabelled_df, iteration):\n",
    "    # Calculates the GAL score associated with each point in a batch of 59 points\n",
    "    # from the unlabelled_df points at a given iteration and returns the new\n",
    "    # set of unlabelled points (U - selected_point) and the selected point along \n",
    "    # with its respective class.\n",
    "    return _select_point_from_batch(discriminative_model, generative_model,\n",
    "                                    unlabelled_df, iteration,\n",
    "                                    _GAL_score)\n",
    "\n",
    "#--------------------------------------------------------------------------------\n",
    "def select_point_from_batch_uncertainty(discriminative_model, generative_model, \n",
    "                                        unlabelled_df, iteration):\n",
    "    return _select_point_from_batch(discriminative_model, generative_model,\n",
    "                                    unlabelled_df, iteration,\n",
    "                                    _uncertainty_score)\n",
    "\n",
    "#--------------------------------------------------------------------------------\n",
    "def select_point_from_batch_likelihood(discriminative_model, generative_model, \n",
    "                                       unlabelled_df, iteration):\n",
    "    return _select_point_from_batch(discriminative_model, generative_model,\n",
    "                                    unlabelled_df, iteration,\n",
    "                                    _likelihood_score)\n",
    "\n",
    "#--------------------------------------------------------------------------------\n",
    "def train_models_using_selected_point(discriminative_model, generative_model,\n",
    "                                      selected_X, selected_y, new_labelled_X,\n",
    "                                      new_labelled_y, labelled_positives):\n",
    "    # Returns updated generative_model and current set of labelled positives.\n",
    "    \n",
    "    # Fit the new point in the SVM.\n",
    "    # EDITED (was using online_fit)\n",
    "    discriminative_model.fit(new_labelled_X, \n",
    "                             new_labelled_y.values.ravel())\n",
    "    \n",
    "    # New labelled positives set = labelled_positive_set U selected_point iff\n",
    "    # selected_point = positive.\n",
    "    if selected_y == POSITIVE_LABEL:\n",
    "        labelled_positives = labelled_positives.append(selected_X)\n",
    "\n",
    "        # Get the best generative model that describes the data.\n",
    "        generative_model = get_optimal_generative_model(labelled_positives)\n",
    "    \n",
    "    return generative_model, labelled_positives\n",
    "\n",
    "#--------------------------------------------------------------------------------\n",
    "def get_optimal_generative_model(all_minority_X):\n",
    "    # Find the optimal number of components for our GMM model given the current\n",
    "    # set of labelled minority examples and return the best model.\n",
    "    n_components = np.arange(1, min(20, len(all_minority_X)))\n",
    "    models = [create_generative_model_instance(n).fit(all_minority_X) \n",
    "              for n in n_components]\n",
    "    bics = [m.bic(all_minority_X) for m in models]\n",
    "    return models[bics.index(min(bics))]\n",
    "\n",
    "#--------------------------------------------------------------------------------\n",
    "def closest_point(centroid, points):\n",
    "    # Find the closest point from a list of points.\n",
    "    distances = (points - np.array(centroid)).pow(2).sum(1).pow(0.5)\n",
    "    minimum_index = distances.idxmin()\n",
    "        \n",
    "    return points.loc[minimum_index]\n",
    "\n",
    "#--------------------------------------------------------------------------------\n",
    "def get_seed_set(data_X, data_y):\n",
    "    # Splits the set of data points into 10% and 90%, where the 10% are points\n",
    "    # selected by selecting the points that are closest to the mode of each\n",
    "    # cluster (where 10% of the size of the dataset is the number of clusters).\n",
    "    # The clusters are created by agglomerative hierarical clustering using the\n",
    "    # ward linkage (i.e. minimal variance of each cluster).\n",
    "    \n",
    "    scaler = MinMaxScaler((-1, 1))\n",
    "    scaled_X = pd.DataFrame(scaler.fit_transform(data_X), index=data_X.index,\n",
    "                            columns=data_X.columns)\n",
    "    \n",
    "    # Here we are wrapping the model with a normalizer so no feature is\n",
    "    # considered more important than another feature.\n",
    "    clustering = _create_model_instance(AgglomerativeClustering(\n",
    "        round(0.1*len(scaled_X))))\n",
    "    \n",
    "    # Get the cluster assignment of each point.\n",
    "    cluster_assignments = clustering.fit_predict(scaled_X)\n",
    "    \n",
    "    nearestCentroid = NearestCentroid()\n",
    "    nearestCentroid.fit(scaled_X, cluster_assignments)\n",
    "    centroids = nearestCentroid.centroids_\n",
    "    \n",
    "    seed_set = pd.DataFrame()\n",
    "    for centroid in centroids:\n",
    "        seed_set = seed_set.append(closest_point(centroid, scaled_X))\n",
    "    \n",
    "    # Make sure we don't have duplicates in our seed set.\n",
    "    seed_set = seed_set.drop_duplicates()\n",
    "    \n",
    "    print('centroids_set shape should be >= seed_set shape. If it doesn\\'t then'\n",
    "          ' there is something wrong.')\n",
    "    print('centroids_set shape = ')\n",
    "    print(centroids.shape)\n",
    "    \n",
    "    print('seed_set shape = ')\n",
    "    print(seed_set.shape)\n",
    "    \n",
    "    return data_X[data_X.index.isin(seed_set.index)], \\\n",
    "           data_y[data_y.index.isin(seed_set.index)]\n",
    "    \n",
    "#--------------------------------------------------------------------------------\n",
    "def calculate_f1_score(discriminative_model, X_test, y_test):\n",
    "    y_pred = discriminative_model.predict(X_test)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    print('F1 score = {}'.format(f1))\n",
    "    return f1\n",
    "\n",
    "#--------------------------------------------------------------------------------\n",
    "def plot_pr_curve(discriminative_model, X_test_, y_test, dataset_name, \n",
    "                  criterion_name):\n",
    "    y_pred_prob = discriminative_model.predict_proba(X_test)\n",
    "    # Plot the Precision-Recall curve.\n",
    "    pr, re, thresholds = precision_recall_curve(y_test, y_pred_prob[:, 1],\n",
    "                                                pos_label=POSITIVE_LABEL)\n",
    "    print('-' * 80)\n",
    "    plt.figure()\n",
    "    plt.step(re, pr, color='b', alpha=0.8, where='post')\n",
    "\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.title('Precision-Recall Curve ({}, AL criterion: {})'\n",
    "              .format(dataset_name, criterion_name))\n",
    "    plt.savefig(os.path.join(SAVE_DIR, 'Pr_Re_{}_{}.jpg'\n",
    "                             .format(dataset_name, criterion_name)))\n",
    "\n",
    "    print('-' * 80)\n",
    "    \n",
    "#--------------------------------------------------------------------------------\n",
    "def plot_F1_curve(F1_scores, dataset_name, criterion_name):\n",
    "    print('-' * 80)\n",
    "    plt.figure()\n",
    "    plt.step(range(0, len(F1_scores), 50), F1_scores[0::50], color='b', \n",
    "             alpha=0.8, where='post')\n",
    "\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('F1-score')\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.title('F1-score vs Active Learning Iterations ({}, AL criterion: {})'\n",
    "              .format(dataset_name, criterion_name))\n",
    "    plt.savefig(os.path.join(SAVE_DIR, 'F1_curve_{}_{}.jpg'\n",
    "                             .format(dataset_name, criterion_name)))\n",
    "\n",
    "    print('-' * 80)\n",
    "    \n",
    "#--------------------------------------------------------------------------------\n",
    "def plot_minority_examples_curve(num_positive_examples, dataset_name, \n",
    "                                 criterion_name):\n",
    "    print('-' * 80)\n",
    "    plt.figure()\n",
    "    plt.step(range(0, len(num_positive_examples)), num_positive_examples, \n",
    "             color='b', alpha=0.8, where='post')\n",
    "\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Number of Labelled Minority Class Examples')\n",
    "    plt.title('Number of Labelled Minority Class Examples vs Active Learning '\n",
    "              'Iterations ({}, AL criterion: {})'\n",
    "              .format(dataset_name, criterion_name))\n",
    "    plt.savefig(os.path.join(SAVE_DIR, 'minority_examples_curve_{}_{}.jpg'\n",
    "                             .format(dataset_name, criterion_name)))\n",
    "\n",
    "    print('-' * 80)\n",
    "\n",
    "#--------------------------------------------------------------------------------\n",
    "def evaluate_active_learning_criterion(criterion, X_seed, y_seed, X_unlabelled,\n",
    "                                       y_unlabelled, X_test, y_test, \n",
    "                                       class_weight=None, \n",
    "                                       dataset_name='ProteinMethylation',\n",
    "                                       criterion_name=''):\n",
    "    \n",
    "    # Initialize the generative model that best describes the positive examples\n",
    "    # we have.\n",
    "    labelled_positives = X_seed.loc[y_seed[CLASS_COLUMN] == POSITIVE_LABEL]\n",
    "    generative_model = get_optimal_generative_model(labelled_positives)\n",
    "    \n",
    "    # Initialize the discriminative model that fits the seed set.\n",
    "    X_labelled = X_seed\n",
    "    y_labelled = y_seed\n",
    "    svc_model = create_discriminative_model_instance(\n",
    "        class_weight=class_weight)\n",
    "    param_dist = {\n",
    "          'model__C': stats.expon(scale=100),\n",
    "          'model__gamma': ['auto'], \n",
    "          'model__kernel': ['rbf', 'poly'],\n",
    "          'model__class_weight': [class_weight],\n",
    "    }\n",
    "    discriminative_model = RandomizedSearchCV(svc_model, \n",
    "                                              param_distributions=param_dist,\n",
    "                                              cv=5,\n",
    "                                              n_iter=100,\n",
    "                                              n_jobs=2,\n",
    "                                              scoring='f1_macro')\n",
    "    discriminative_model.fit(X_seed, y_seed.values.ravel())\n",
    "    \n",
    "    print(discriminative_model.classes_)\n",
    "    # Iterate through the entire set of unlabelled data.\n",
    "    # On each iteration do the following:\n",
    "    # 1) select the most informative point based on the criterion.\n",
    "    # 2) train the models.\n",
    "    # 3) Record the number of positive examples in the current labelled set.\n",
    "    # 4) Record the F1 score of the classifier at the end of each iteration.\n",
    "    num_positive_examples = []\n",
    "    F1_scores = []\n",
    "    unlabelled_df = X_unlabelled.join(y_unlabelled)\n",
    "    for iteration in range(0, len(unlabelled_df)):\n",
    "        unlabelled_df, selected_X, selected_y = criterion(discriminative_model, \n",
    "                                                          generative_model, \n",
    "                                                          unlabelled_df, \n",
    "                                                          iteration)\n",
    "        # Add the new selected point to the labelled set of data.\n",
    "        X_labelled = X_labelled.append(selected_X)\n",
    "        y_labelled = y_labelled.append(pd.Series({CLASS_COLUMN: selected_y}, \n",
    "                                                 name=selected_X.name))\n",
    "        # print('Selected class = {}'.format(selected_y))\n",
    "        \n",
    "        # Train the models and update the set of labelled positives if the new\n",
    "        # example is positive.\n",
    "        generative_model, labelled_positives = train_models_using_selected_point(\n",
    "            discriminative_model, generative_model, selected_X, selected_y, \n",
    "            X_labelled, y_labelled, labelled_positives)\n",
    "    \n",
    "        num_positive_examples.append(len(labelled_positives))\n",
    "        \n",
    "        \n",
    "        F1_scores.append(calculate_f1_score(discriminative_model, X_test, \n",
    "                                            y_test))\n",
    "        # Uncomment this for a test run.\n",
    "        # if iteration == 100:\n",
    "        #     break\n",
    "    \n",
    "    # Plot the F-score vs iterations curve.\n",
    "    plot_F1_curve(F1_scores, dataset_name, criterion_name)\n",
    "    \n",
    "    # Plot the number of minority examples in labelled set vs iterations curve.\n",
    "    plot_minority_examples_curve(num_positive_examples, dataset_name, \n",
    "                                 criterion_name)\n",
    "\n",
    "    # Plot the precision recall curve of the final classifier.\n",
    "    plot_pr_curve(discriminative_model, X_test, y_test, dataset_name,\n",
    "                  criterion_name)\n",
    "\n",
    "#--------------------------------------------------------------------------------\n",
    "def get_precision_std(tp, n):\n",
    "    p = float(tp) / n\n",
    "    variance_of_sum = p * (1 - p) / n\n",
    "    std = variance_of_sum ** 0.5\n",
    "    return std\n",
    "\n",
    "#--------------------------------------------------------------------------------\n",
    "def get_abalone():\n",
    "    \"\"\"Loads abalone dataset, maps gender feature to binary features, adds\n",
    "    new label to create abalone19 imbalanced binary classification dataset.\"\"\"\n",
    "    ORIGINAL_CLASS_COL = 'Class_number_of_rings'\n",
    "    raw_data = import_csv(csv_path_training)\n",
    "    genders = list(raw_data.ix[:, 'Sex'])\n",
    "    cts_data = raw_data.drop(labels='Sex', axis=1)\n",
    "\n",
    "    # initialize & fit preprocesser\n",
    "    lbz = LabelBinarizer()\n",
    "    lbz.fit(genders)\n",
    "\n",
    "    # encode categorical var\n",
    "    encoded_genders = pd.DataFrame(lbz.transform(genders))\n",
    "    encoded_genders.columns = ['Sex_' + k for k in lbz.classes_]\n",
    "\n",
    "    # recombine encoded data & return\n",
    "    new_data = pd.concat(objs=[encoded_genders, cts_data], axis=1)\n",
    "    new_data[CLASS_COLUMN] = raw_data[ORIGINAL_CLASS_COL].map(\n",
    "        lambda k: 1 if k == ABALONE_AGE else 0)               # binary clf task\n",
    "    \n",
    "    new_data = new_data.drop(ORIGINAL_CLASS_COL, axis=1)\n",
    "\n",
    "    pos_recs = new_data[CLASS_COLUMN].sum()\n",
    "    print('total pos class (should be 32) = {}\\n'.format(\n",
    "        pos_recs))\n",
    "\n",
    "    return new_data\n",
    "\n",
    "#--------------------------------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    csv_path_training = os.path.join(BASE_DIR, CSV_FILE_TRAINING)\n",
    "#     csv_path_calibration = os.path.join(BASE_DIR, CSV_FILE_CALIBRATION)\n",
    "\n",
    "    # All of our data collected.\n",
    "    data = get_abalone()\n",
    "    \n",
    "    # Drop id column from data.\n",
    "#     data = data.drop(['id'], 1)\n",
    "\n",
    "    # Separate features from their corresponding class.\n",
    "    y = data.pop(CLASS_COLUMN).to_frame()\n",
    "    X = data\n",
    "    \n",
    "    # Save 50% of the data for testing.\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, \n",
    "                                                        test_size=0.5)\n",
    "    \n",
    "    # Get the seed set using agglomeratice hierarichal clustering.\n",
    "    X_seed, y_seed = get_seed_set(X_train, y_train)\n",
    "    \n",
    "    # Initialize the unlabelled set of data.\n",
    "    X_unlabelled = X_train[~X_train.isin(X_seed).all(1)]\n",
    "    y_unlabelled = y_train[y_train.index.isin(X_unlabelled.index)]\n",
    "    \n",
    "    print('Is there a duplicated index in the unlabelled set?')\n",
    "    print(True in X_unlabelled.index.duplicated())\n",
    "    \n",
    "    print('Is there a duplicated index in the seed set?')\n",
    "    print(True in X_seed.index.duplicated())\n",
    "    \n",
    "    print('Is there a positive example in our seed set?')\n",
    "    print(y_seed.isin([POSITIVE_LABEL]).any().any())\n",
    "    \n",
    "    print('Do X_unlabelled and y_unlabelled have the same size?')\n",
    "    print('X_unlabelled = {},\\t y_unlabelled = {}'.format(len(X_unlabelled),\n",
    "                                                          len(y_unlabelled)))\n",
    "    \n",
    "    # Segregate the negative and positive seed examples.\n",
    "    negative_seed = X_seed.loc[y_seed[CLASS_COLUMN] != POSITIVE_LABEL]\n",
    "    positive_seed = X_seed.loc[y_seed[CLASS_COLUMN] == POSITIVE_LABEL]\n",
    "    \n",
    "    # Negative cost = # of pos in seed set/seed set size\n",
    "    negative_cost = len(positive_seed) / len(X_seed)\n",
    "    \n",
    "    # Positive cost = # of negative in seed set/seed set size\n",
    "    positive_cost = len(negative_seed) / len(X_seed)\n",
    "    \n",
    "    print('Negative example cost = {}'.format(negative_cost))\n",
    "    print('Positive example cost = {}'.format(positive_cost))\n",
    "    \n",
    "    print('Number of Positive examples in seed set = {}'\n",
    "          .format(len(positive_seed)))\n",
    "    \n",
    "    criterion = select_point_from_batch_GAL\n",
    "    evaluate_active_learning_criterion(criterion, X_seed, y_seed, X_unlabelled,\n",
    "                                       y_unlabelled, X_test, y_test, \n",
    "                                       class_weight={1: len(negative_seed) / float(len(positive_seed))},\n",
    "                                       dataset_name='Abalone16',\n",
    "                                       criterion_name='GAL_weighted')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
